{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fa0538e",
   "metadata": {},
   "source": [
    "# Config\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "config_path = \"./config/train.json\"\n",
    "if not os.path.exists(config_path):\n",
    "  raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "  try:\n",
    "    config = json.load(f)\n",
    "  except json.JSONDecodeError as e:\n",
    "    raise ValueError(f\"Error parsing config file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c1b7a",
   "metadata": {},
   "source": [
    "# Model Class\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "class DuelingDQN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size=config[\"hidden_size\"], output_size=2, num_layers=config[\"num_layers\"]):\n",
    "    super(DuelingDQN, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=input_size,\n",
    "      hidden_size=hidden_size,\n",
    "      num_layers=num_layers,\n",
    "      batch_first=True,\n",
    "      dropout=config[\"dropout_rate\"],\n",
    "      bidirectional=False\n",
    "    )\n",
    "    self.ln = nn.LayerNorm(hidden_size)\n",
    "    self.attention = nn.MultiheadAttention(hidden_size, num_heads=config[\"attention_heads\"], batch_first=True)\n",
    "    self.value_stream = nn.Sequential(\n",
    "      nn.Linear(hidden_size, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.3),\n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 1)\n",
    "    )\n",
    "    self.advantage_stream = nn.Sequential(\n",
    "      nn.Linear(hidden_size, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.3),\n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, output_size)\n",
    "    )\n",
    "    self.apply(self._InitWeights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1e35f",
   "metadata": {},
   "source": [
    "### Initialize Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelInitWeights(self, module):\n",
    "  if isinstance(module, nn.Linear):\n",
    "    nn.init.xavier_uniform_(module.weight)\n",
    "    nn.init.constant_(module.bias, 0)\n",
    "  elif isinstance(module, nn.LSTM):\n",
    "    for name, param in module.named_parameters():\n",
    "      if 'weight' in name:\n",
    "        nn.init.xavier_uniform_(param)\n",
    "      elif 'bias' in name:\n",
    "        nn.init.constant_(param, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bd4db",
   "metadata": {},
   "source": [
    "### Model Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49727790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelforward(self, x):\n",
    "  batch_size = x.size(0)\n",
    "\n",
    "  # LSTM processing\n",
    "  lstm_out, _ = self.lstm(x)\n",
    "  lstm_out = self.ln(lstm_out)\n",
    "\n",
    "  # Self-attention\n",
    "  attended_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "\n",
    "  # Use the last time step\n",
    "  final_hidden = attended_out[:, -1, :]\n",
    "\n",
    "  # Dueling streams\n",
    "  value = self.value_stream(final_hidden)\n",
    "  advantage = self.advantage_stream(final_hidden)\n",
    "\n",
    "  # Combine value and advantage\n",
    "  q_values = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "\n",
    "  return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb13ac",
   "metadata": {},
   "source": [
    "### Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc615415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelSave(self, file_path):\n",
    "  os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "  torch.save({\n",
    "      'model_state_dict': self.state_dict(),\n",
    "      'input_size': self.input_size,\n",
    "      'hidden_size': self.hidden_size\n",
    "  }, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90f097",
   "metadata": {},
   "source": [
    "### Model Method Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DuelingDQN.forwardpass = modelforward\n",
    "DuelingDQN._InitWeights = modelInitWeights\n",
    "DuelingDQN.save = modelSave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a9550",
   "metadata": {},
   "source": [
    "# Environment Class\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35347c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MetaFilterEnvironment:\n",
    "  def __init__(self, drawdown_series: np.ndarray, trade_log, window_size=config[\"window_size\"]):\n",
    "    self.drawdown = drawdown_series.astype(np.float32)\n",
    "    self.trade_log = trade_log\n",
    "    self.window_size = window_size\n",
    "    self.total_steps = len(drawdown_series)\n",
    "    self.current_step = window_size\n",
    "    self.strategy_active = False\n",
    "    self.state_history = []\n",
    "    self.activity_flags = np.zeros(self.total_steps, dtype=bool)\n",
    "    self.native_equity_curve = []\n",
    "    self.ai_equity_curve = []\n",
    "    self.switch_count = 0\n",
    "    self.last_action = 0\n",
    "    self.consecutive_same_action = 0\n",
    "    self.total_native_pnl = 0.0\n",
    "    self.total_ai_pnl = 0.0\n",
    "    self.max_drawdown_native = 0.0\n",
    "    self.max_drawdown_ai = 0.0\n",
    "    self.volatility_penalty = 0.0\n",
    "    self.pnl_values = self._extract_pnl_values(trade_log)\n",
    "    self.additional_features = self._calculateFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ac57d",
   "metadata": {},
   "source": [
    "### Step Forward in Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb96c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envforward(self, action: int):\n",
    "  if action == self.last_action:\n",
    "    self.consecutive_same_action += 1\n",
    "  else:\n",
    "    self.consecutive_same_action = 0\n",
    "    if self.current_step > self.window_size:\n",
    "      self.switch_count += 1\n",
    "  self.last_action = action\n",
    "\n",
    "  if action == 1:\n",
    "    self.strategy_active = True\n",
    "  elif action == 0:\n",
    "    self.strategy_active = False\n",
    "\n",
    "  self.activity_flags[self.current_step] = self.strategy_active\n",
    "\n",
    "  current_pnl = self.pnl_values[self.current_step]\n",
    "  self.total_native_pnl += current_pnl\n",
    "  self.native_equity_curve.append(self.total_native_pnl)\n",
    "\n",
    "  if self.strategy_active:\n",
    "    self.total_ai_pnl += current_pnl\n",
    "  self.ai_equity_curve.append(self.total_ai_pnl)\n",
    "\n",
    "  if len(self.native_equity_curve) > 1:\n",
    "    peak_native = max(self.native_equity_curve)\n",
    "    current_dd_native = (peak_native - self.total_native_pnl) / max(abs(peak_native), 1)\n",
    "    self.max_drawdown_native = max(self.max_drawdown_native, current_dd_native)\n",
    "\n",
    "  if len(self.ai_equity_curve) > 1:\n",
    "    peak_ai = max(self.ai_equity_curve)\n",
    "    current_dd_ai = (peak_ai - self.ai_pnl) / max(abs(peak_ai), 1)\n",
    "    self.max_drawdown_ai = max(self.max_drawdown_ai, current_dd_ai)\n",
    "\n",
    "  reward = self._calculateReward(current_pnl, action)\n",
    "  done = self.current_step >= self.total_steps - 1\n",
    "  self.current_step += 1\n",
    "  next_state = self._get_enhanced_state() if not done else self._get_enhanced_state()\n",
    "\n",
    "  return next_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f5123",
   "metadata": {},
   "source": [
    "### Reset Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envreset(self):\n",
    "  self.current_step = self.window_size\n",
    "  self.strategy_active = False\n",
    "  self.activity_flags = np.zeros(self.total_steps, dtype=bool)\n",
    "  self.native_equity_curve = []\n",
    "  self.ai_equity_curve = []\n",
    "  self.switch_count = 0\n",
    "  self.last_action = 0\n",
    "  self.consecutive_same_action = 0\n",
    "  self.total_native_pnl = 0.0\n",
    "  self.total_ai_pnl = 0.0\n",
    "  self.max_drawdown_native = 0.0\n",
    "  self.max_drawdown_ai = 0.0\n",
    "  self.volatility_penalty = 0.0\n",
    "  self.state_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc988945",
   "metadata": {},
   "source": [
    "### Calculate Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0138cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envcalculateReward(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f2c98",
   "metadata": {},
   "source": [
    "### Calculate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e78b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envcalculateFeatures(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1b341",
   "metadata": {},
   "source": [
    "### Environment Method Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaFilterEnvironment.forward = envforward\n",
    "MetaFilterEnvironment.reset = envreset\n",
    "MetaFilterEnvironment._calculateReward = envcalculateReward\n",
    "MetaFilterEnvironment._calculateFeatures = envcalculateFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed05f9",
   "metadata": {},
   "source": [
    "# Agent Class\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaFilterAgent:\n",
    "  def __init__(self, drawdown_data, trade_log, model_path=\"\", window_size=config[\"window_size\"]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b9069",
   "metadata": {},
   "source": [
    "### Model Forward Pass Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(self, state, training=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c1ce7",
   "metadata": {},
   "source": [
    "### Train Single Episode Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_episode(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df97704f",
   "metadata": {},
   "source": [
    "### Train All Episodes Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b83a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, episodes=config[\"episodes\"], eval_every=config[\"eval_every\"]):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfdaca",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b9602",
   "metadata": {},
   "source": [
    "### Evaluate Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(self):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecad00e",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(self, path):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea4475",
   "metadata": {},
   "source": [
    "### Agent Method Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaFilterAgent.get_action = get_action\n",
    "MetaFilterAgent.train_episode = train_episode\n",
    "MetaFilterAgent.train = train\n",
    "MetaFilterAgent.test = test\n",
    "MetaFilterAgent.evaluate_episode = evaluate_episode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
